---
pagetitle: Release Notes for STM32_AI_Runtime Middleware Component
lang: en
---

::: {.row}
::: {.col-sm-12 .col-lg-4}

::: {.card .fluid}

::: {.sectione .dark}
<center>
# <small>Release Notes for</small> **STM32_AI_Runtime Library**
Copyright &copy; 2022 STMicroelectronics
    
[![ST logo](../../../_htmresc/st_logo.png)](https://www.st.com){.logo}
</center>
:::
:::

# Purpose

STM32_AI_Runtime is a neural network library optimized for STM32.

Here is the list of references to user documents:

- [UM2526](https://www.st.com/content/ccc/resource/technical/document/user_manual/group1/69/bb/ec/5d/78/16/43/ce/DM00570145/files/DM00570145.pdf/jcr:content/translations/en.DM00570145.pdf) : Getting started with X-CUBE-AI Expansion Package for Artificial Intelligence (AI)
:::

::: {.col-sm-12 .col-lg-8}
# Update History

::: {.collapse}
<input type="checkbox" id="collapse-section7" checked aria-hidden="true">
<label for="collapse-section7" aria-hidden="true">__V7.3.0 / October-2022__</label>
<div>

## Main Changes

-  ONNX import - support model with input fixed shape and output with undefined shape

# Major bug fixes

- fix support of concat with large number of inputs
- fix Softmax on non-axis channel

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V7.3.0

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section6" aria-hidden="true">
<label for="collapse-section6" aria-hidden="true">__V7.1.0 / 4-January-2022__</label>
<div>

## Main Changes

- add support for new layers
  - Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, RandomForest, ExtraTree, GradientBoosting, HistGradientBoosting, TreeEnsembleClassifier, ReduceLogSumExp, Scaler, TreeEnsembleClassifier, LinearClassifier, Where, Clip (ONNX-ML/ONNX)
  - TFOpLambda, stateful GRU Layer (Keras)
  - SPLIT_V, ReverseV2, SQUARED_DIFFERENCE (TFLite)
- multi-heap support support allowing to split the activations buffer in different memory segments and to have first a better usage of the device with fragmented memory devices (no contignuous memory) like the STM32H7 series.
- add support for STM32 ARM Cortex M0 and ARM Cortex M0+ based
- upgrade TensorFlow lite runtime 2.7.0 and ONNX 1.9

# Major bug fixes

- support of weights for the Keras custom layers
- support for PACK layer with dimensions>4
- support for unpack& transpose layer with dimensions>4
- fix compuation of the requested arena size for TFLM runtime
- improve report of the unsupported operators for TFLM runtime
- improve support of ONNX LSTM operator (Now multiple outputs (final state, hidden state, cell state) for LSTM are allowed)
- improve shared axes support in PReLU (support the case where 1 is present in the middle of input shape)
- improve constant propagation for Pack and Reduce operators
- for ONNX model, sottmax not on channel axis is now supported by adding a transpose before and after softmax
- improve support of 2D ONNX MatMul operator with multiple inputs (second input not constant)

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V7.1.0

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section5" aria-hidden="true">
<label for="collapse-section5" aria-hidden="true">__V6.0.0 / 10-March-2021__</label>
<div>

## Main Changes

- new operators/layers
  - KERAS: Average, Custom layer, Lambda wrapper: tf.math.abs,  tf.math.acos, tf.gather.. 25+
  - ONNX: ConstantOfShape, DequantizeLinear, Equal, Gather, Greater, GreaterOrEqual, Identity, Less,
      LessOrEqual, Mean, Neg, Not, Or, QLinearConv, QLinearMatMul, QuantizeLinear, ReduceL1,
      ReduceL2, ReduceSumSquare, Shape, Xor
  - TFLITE: EQUAL, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, L2_NORMALIZATION, LESS, LESS_EQUAL,
      LOGICAL_AND, LOGICAL_NOT, LOGICAL_OR,
      MIRROR_PAD, PACK, REDUCE_ANY, REDUCE_MAX, REDUCE_MIN, REDUCE_PROD, SHAPE, SQUARE, TILE,
      UNIDIRECTIONAL_SEQUENCE_LSTM
- remove Qmn format support

# Major bug fixes

- fix problems with shape of RepeatVector and recurrent layers
- fix TFlite L2_Normalization import
- fix bug on Conv2D float margin computation
- fix problem when scale bias layer is merged in convolutional layer with zero bias
- fix observer API to model with only one layer
- enhance eltwise optimization
- improve integer clip support
- fix ResizeBilinear TFLite op (half_pixel_centers parameter support for +TF2 version)

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V6.0.0

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section4" aria-hidden="true">
<label for="collapse-section4" aria-hidden="true">__V5.2.0 / 5-October-2020__</label>
<div>

## Main Changes

- adding support for **relocatable binary model**
- TFLite and Keras importers are now fully based on **TensorFlow 2.3**
- remove the Keras.io support
- up-to Keras version 2.4.0 model can be imported
- add support to allocate the output buffers in activations buffer
- performance improvement (with conv2D int8) wherever weights location (in internal or external flash)
- bugs fixes / **no new operator**

**Note** -- The support of the following deprecated toolboxes is not maintained in future releases:

- Lasagne: [https://lasagne.readthedocs.io/en/latest/][LASAGNE]
- Caffe: [https://caffe.berkeleyvision.org/][CAFFE]
- ConvNetJs: [https://cs.stanford.edu/people/karpathy/convnetjs/][CONV_NET_JS]

**Note** -- Qm,n arithmetic is a legacy support, it will be deprecated in future releases.

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V5.2.0

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section3" aria-hidden="true">
<label for="collapse-section3" aria-hidden="true">__V5.1.2 / 24-July-2020__</label>
<div>

## Main Changes

- Enhancements of the User Interface
  - New graph to display the C-graph (operators and associated tensors)
  - New graph to display the usage of the "activations" buffer

- C-Code generation
  - Adding support to generate a c-array by weight/bias tensor
  - Adding textual c-graph description (operators and associated tensors) in the reports
  - Lighter network-runtime library support. Granularity of the inference kernel functions are
    aligned on the used integer scheme to decrease the code size.
  - Improvement of the memory peak usage (RAM and ROM size)

- Embedded inference client API extension
  - Adding platform observer API

- Validation
  - Adding support for int8/uint8 validation files

- System performance application
  - Adding executing time by layer

- Documentation
  - Adding specific article for the quantization a spects

**Note** -- User should be aware that *Qm,n* arithmetic is a legacy support, it will
            be deprecated in the future release.

## Major bug fixes and improvement

- adding ONNX Softmax, Hardmax, LogSoftmax, Resize operators
- upgrading subset of operators up-to Opset to 10 support of ONNX 1.6
- adding batch normalization and mul/add support for integer layers
- adding Keras simple RNNs support
- adding support for quantized concat operator
- removing system heap usage for recurrent layers
- fixing support for Keras GRU/LSTM/RNN layers when use_bias==False
- fixing support for Keras GRU/LSTM layers with non-default nonlinear function
- fixing ONNX shape interpretation (Concat and Slice) for 2D tensors
- fixing duplicated inputs for elementwise operators
- fixing support for TFLite/ONNX model with multiple IO
- fixing MACC calculation for ONNX GEMM layers
- improving parsing of TFLite reshape operator
- fixing parsing of Keras RepeatVector operator

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V5.1.2

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section2" aria-hidden="true">
<label for="collapse-section2" aria-hidden="true">__V5.0.0 / 23-December-2019__</label>
<div>			

## Main Changes

- Support of ONNX floating-point network
  - A subset of operators from Opset 7, 8 and 9 of ONNX 1.6 is supported

- Adding "per-channel" support for quantized model
  - Enhanced support for Post-quantized and training-aware TensorFlow lite models
  - Keras post-quantization process update

- Support of Mutiple IO network
  - Model for multiple IO are now fully supported

- Bug fixes and enhancement
  - Improvement of the RAM usage

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V5.0.0

</div>
:::

::: {.collapse}
<input type="checkbox" id="collapse-section1" aria-hidden="true">
<label for="collapse-section1" aria-hidden="true">__V4.0.0 / 19-July-2019__</label>
<div>			

## Main Changes

### **First official release of STM32_AI library**

## Contents

- Neural Network library generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html)  V4.0.0

</div>
:::

</div>
:::

</div>
:::


<footer class="sticky">
For complete documentation on **STM32 Microcontrollers **,
visit: [www.st.com](http://www.st.com/STM32)

This release note uses up to date web standards and, for this reason, should not
be opened with Internet Explorer but preferably with popular browsers such as
Google Chrome, Mozilla Firefox, Opera or Microsoft Edge.
</footer>
